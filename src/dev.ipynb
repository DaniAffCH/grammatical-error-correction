{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jflegDataset import JflegDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from _utils import tokenizerSetup, SpecialToken\n",
    "from model import S2S\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TRAIN_PATH = \"dataset/train.csv\"\n",
    "VAL_PATH = \"dataset/eval.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[50259, 50259, 50259,  1026,   481,  6290,   287,   262],\n",
       "        [   40,   765,   284,  4483,   257,  1263,  9396,   286],\n",
       "        [50259, 50259, 50259, 50259, 50259,  3666,  3290,   318]]), 'attention_mask': tensor([[0, 0, 0, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 1, 1, 1]])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tokenizerSetup()\n",
    "\n",
    "sentences = [\"It will rain in the\",\n",
    "            \"I want to eat a big bowl of\",\n",
    "            \"My dog is\"]\n",
    "\n",
    "a = tokenizer(sentences, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "class JflegDataset(Dataset):\n",
    "    def __init__(self, path, tokenizer, max_len=128) -> None:\n",
    "        super().__init__()\n",
    "        self.data = pd.read_csv(path)\n",
    "        self.tokenizer = tokenizer\n",
    "        self._preprocess()\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def _preprocess(self):\n",
    "        self.data = self.data.groupby(\n",
    "            'input')['target'].agg(np.array).reset_index()\n",
    "        self.data[\"input\"] = self.data[\"input\"].str.replace(\n",
    "            r'^grammar: ', '', regex=True)\n",
    "\n",
    "    def _process_sequence(self, sequence):\n",
    "        sequence = f\"{self.tokenizer.bos_token} {sequence} {self.tokenizer.eos_token}\"\n",
    "        result = self.tokenizer(sequence, return_tensors=\"pt\",\n",
    "                                padding=\"max_length\", truncation=True, max_length=self.max_len)\n",
    "        result = {key: value.squeeze() for key, value in result.items()}\n",
    "        return result\n",
    "\n",
    "    def _right_shift(self, original_tensor: torch.Tensor, shift, filling_value) -> torch.Tensor:\n",
    "        head = torch.full((shift,), filling_value)\n",
    "        return torch.cat((head, original_tensor[:-shift]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.size//2\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input = self.data.iloc[index][\"input\"]\n",
    "        input = self._process_sequence(input)\n",
    "\n",
    "        target_text_list = self.data.iloc[index][\"target\"]\n",
    "        target_out = random.choice(target_text_list)\n",
    "        target_out = self._process_sequence(target_out)\n",
    "\n",
    "        bos_token_index = torch.where(\n",
    "            target_out[\"input_ids\"] == self.tokenizer.bos_token_id)[0]\n",
    "\n",
    "        target_in = {\n",
    "            \"input_ids\": target_out[\"input_ids\"].clone(),\n",
    "            \"attention_mask\": target_out[\"attention_mask\"].clone()\n",
    "        }\n",
    "\n",
    "        target_in[\"input_ids\"][bos_token_index] = self.tokenizer.pad_token_id\n",
    "        target_in[\"attention_mask\"][bos_token_index] = 0.\n",
    "\n",
    "        return input, target_in, target_out\n",
    "\n",
    "    def decode(self, embedding):\n",
    "        return self.tokenizer.decode(embedding, skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = JflegDataset(TRAIN_PATH, tokenizer)\n",
    "ds_eval = JflegDataset(VAL_PATH, tokenizer)\n",
    "\n",
    "dl_train = DataLoader(ds_train, batch_size=1)\n",
    "dl_eval = DataLoader(ds_eval, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
       "           50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
       "           50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
       "           50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
       "           50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
       "           50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
       "           50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
       "           50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
       "           50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
       "           50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
       "           50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
       "             352,   767,    12,    20,   657,   661,  5526,   284,  2421,   477,\n",
       "            1398,   290, 21792,  1398,   764,   220,   220, 50258]]),\n",
       "  'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1]])},\n",
       " {'input_ids': tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
       "           50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
       "           50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
       "           50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
       "           50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
       "           50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
       "           50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
       "           50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
       "           50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
       "           50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
       "           50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50257,\n",
       "             352,   767,    12,    20,   657,   661,  5526,   284,  2421,   477,\n",
       "            1398,   290, 21792,  1398,   764,   220,   220, 50258]]),\n",
       "  'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1]])})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(dl_train)\n",
    "next(it)\n",
    "input, target_in, target_out = next(it)\n",
    "\n",
    "target_in, target_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import math\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    # https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2)\n",
    "                             * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "\n",
    "class S2S(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken: int, d_model: int):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, 0.1)\n",
    "        self.embedding = TokenEmbedding(ntoken, d_model)\n",
    "\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model,\n",
    "            nhead=4,\n",
    "            num_encoder_layers=6,\n",
    "            num_decoder_layers=6,\n",
    "            dim_feedforward=1024,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.head = nn.Linear(d_model, ntoken)\n",
    "        self.sm = nn.Softmax(dim=0)\n",
    "\n",
    "    def forward(self, input: Tensor, target: Tensor, input_mask: Tensor, target_mask: Tensor) -> Tensor:\n",
    "        input_mask = input_mask.bool()\n",
    "        target_mask = target_mask.bool()\n",
    "\n",
    "        src = self.embedding(input)\n",
    "        src = self.pos_encoder(src)\n",
    "\n",
    "        target = self.embedding(target)\n",
    "        target = self.pos_encoder(target)\n",
    "\n",
    "        out_sequence_len = target.size(1)\n",
    "\n",
    "        trmask = torch.triu(torch.ones(\n",
    "            out_sequence_len, out_sequence_len) * float(\"-inf\"), diagonal=1)\n",
    "\n",
    "\n",
    "        encoded = self.transformer.encoder(\n",
    "            src, src_key_padding_mask=input_mask)\n",
    "\n",
    "        decoded = self.transformer.decoder(\n",
    "            target, memory=encoded, tgt_mask=trmask,tgt_key_padding_mask=target_mask)\n",
    "\n",
    "        out = self.head(decoded)\n",
    "\n",
    "        return self.sm(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128])\n",
      "out.shape=torch.Size([1, 128, 50260])\n"
     ]
    }
   ],
   "source": [
    "model = S2S(tokenizer.vocab_size + len(SpecialToken), 768)\n",
    "\n",
    "for input, target_in, target_out in dl_train:\n",
    "    print(target_in[\"input_ids\"].shape)\n",
    "    out = model(input[\"input_ids\"], target_in[\"input_ids\"], input[\"attention_mask\"], target_in[\"attention_mask\"])\n",
    "    i = out.argmax(2)\n",
    "\n",
    "    print(f\"{out.shape=}\")\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
